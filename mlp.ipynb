{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class irisMlp(nn.Module):\n",
    "    def __init__(self,input_size = 4,hidden_size = 100, output_size = 3):\n",
    "        super(irisMlp,self).__init__()\n",
    "\n",
    "        self.hidden = nn.Linear(input_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(hidden_size,output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "    def train_model(self, train_loader, learning_rate=0.001, epochs=25):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Training loop\n",
    "        self.train()  # Set the model to training mode\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for inputs, labels in train_loader:\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Backward pass and optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Track loss\n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            # Print the average loss for the epoch\n",
    "            print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
    "    \n",
    "    def test_model(self, test_loader):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Testing loop\n",
    "        self.eval()  # Set the model to evaluation mode\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        test_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                # Forward pass\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                # Get predictions\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Print accuracy and average loss\n",
    "        print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "        print(f\"Test Loss: {test_loss / len(test_loader):.4f}\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 1.6190\n",
      "Epoch [2/25], Loss: 1.1345\n",
      "Epoch [3/25], Loss: 1.1005\n",
      "Epoch [4/25], Loss: 1.0306\n",
      "Epoch [5/25], Loss: 0.9299\n",
      "Epoch [6/25], Loss: 0.8856\n",
      "Epoch [7/25], Loss: 0.8350\n",
      "Epoch [8/25], Loss: 0.7921\n",
      "Epoch [9/25], Loss: 0.7511\n",
      "Epoch [10/25], Loss: 0.7183\n",
      "Epoch [11/25], Loss: 0.6854\n",
      "Epoch [12/25], Loss: 0.6606\n",
      "Epoch [13/25], Loss: 0.6335\n",
      "Epoch [14/25], Loss: 0.6118\n",
      "Epoch [15/25], Loss: 0.5883\n",
      "Epoch [16/25], Loss: 0.5655\n",
      "Epoch [17/25], Loss: 0.5541\n",
      "Epoch [18/25], Loss: 0.5222\n",
      "Epoch [19/25], Loss: 0.5251\n",
      "Epoch [20/25], Loss: 0.4973\n",
      "Epoch [21/25], Loss: 0.4765\n",
      "Epoch [22/25], Loss: 0.4761\n",
      "Epoch [23/25], Loss: 0.4688\n",
      "Epoch [24/25], Loss: 0.4514\n",
      "Epoch [25/25], Loss: 0.4330\n",
      "Test Accuracy: 97.78%\n",
      "Test Loss: 0.3718\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "model = irisMlp()\n",
    "\n",
    "# Load and preprocess the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "inputs = torch.from_numpy(iris.data).float()\n",
    "labels = torch.from_numpy(iris.target).long()\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create DataLoader for train and test sets\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=16, shuffle=False)\n",
    "\n",
    "# Train and test the model\n",
    "model.train_model(train_loader)\n",
    "model.test_model(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NNstuff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
